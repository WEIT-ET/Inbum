{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zo5OSHwBIFgm",
        "outputId": "4cbb2d68-ef29-47d2-b9aa-f2cbd3daee5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import sent_tokenize"
      ],
      "metadata": {
        "id": "Ycu-mrNAIMTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVg_AjHQomoZ",
        "outputId": "c4013021-32b2-4021-c5ad-8d6d8e2231f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "textsample = 'the matrix is everywhere its all around us, here even in this in room'\n",
        "\n",
        "sentences = sent_tokenize(text=textsample)"
      ],
      "metadata": {
        "id": "e8VJs4eDph3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(sentences))\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8vF_Mbfpwcs",
        "outputId": "32372e08-5243-46d8-8a86-f58dffd486df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "['the matrix is everywhere its all around us, here even in this in room']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import sparse\n",
        "\n",
        "dense = np.array([[[3,0,1],[0,2,0]]])\n",
        "data = np.array([3,1,2])\n",
        "\n",
        "row_pos = np.array([0,0,1])\n",
        "col_pos = np.array([0,2,1])\n",
        "\n",
        "sparse_coo = sparse.coo_matrix((data, (row_pos, col_pos)))"
      ],
      "metadata": {
        "id": "pe7iXmgHRTcr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sparse_coo.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9q1n2Yslazo0",
        "outputId": "1f5711c6-e322-4757-9b96-852ec81f8c0a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3, 0, 1],\n",
              "       [0, 2, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 텍스트 분류 실습 예제"
      ],
      "metadata": {
        "id": "lv1k9JA_d_2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using fetch_20newsgropus api\n",
        "# And make CSR and using Logistic Regression\n",
        "# GridSearchCV and using scikit-learn Pipeline\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "news_data = fetch_20newsgroups(subset = 'all', random_state =111)"
      ],
      "metadata": {
        "id": "YR7yPHCpeEjK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 한 줄 처리\n",
        "pd.Series(news_data.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4asPOvPgqqi",
        "outputId": "da2cd9fb-4c0a-4581-f036-aa6814b77917"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         6\n",
              "1        13\n",
              "2         6\n",
              "3         9\n",
              "4         5\n",
              "         ..\n",
              "18841     6\n",
              "18842    12\n",
              "18843     1\n",
              "18844    12\n",
              "18845    10\n",
              "Length: 18846, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_news = fetch_20newsgroups(subset = 'train', remove = ('headers', 'footers','quotes'), random_state = 111)"
      ],
      "metadata": {
        "id": "E9QJYAcjjNDq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train  = train_news.data\n",
        "y_train  = train_news.target\n",
        "\n",
        "test_news = fetch_20newsgroups(subset='test',  remove = ('headers', 'footers','quotes'), random_state = 111)\n",
        "X_test = test_news.data\n",
        "y_test = test_news.target\n",
        "\n",
        "len(test_news.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBAhKzg3j244",
        "outputId": "36d02c67-a5e8-48e7-e511-1e81b1e69e6d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7532"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# Import Model and Training model using default Parameter\n",
        "cnt_vect = CountVectorizer()\n",
        "cnt_vect.fit(X_train)\n",
        "X_train_cnt_vect =cnt_vect.transform(X_train)\n",
        "X_test_cnt_vect= cnt_vect.transform(X_test)"
      ],
      "metadata": {
        "id": "pqJUBYe1lCpJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'학습 데이터 텍스트 shape: {X_train_cnt_vect.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cH0awVsElvgm",
        "outputId": "d21425d3-0d38-4492-e68b-53436bcbc36a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 데이터 텍스트 shape: (11314, 101631)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "lr_classfier = LogisticRegression(solver = 'liblinear')\n",
        "lr_classfier.fit(X_train_cnt_vect, y_train)\n",
        "pred = lr_classfier.predict(X_test_cnt_vect)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "sPP1Is_8mWan",
        "outputId": "f22bb326-3afe-4002-b438-d0f432db5b70"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-3cf02a0d1ce5>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mlr_classfier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_cnt_vect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_classfier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_cnt_vect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'예측 정확도 {accuracy_score(y_test, pred):..3}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: Format specifier missing precision"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'예측 정확도 {round(accuracy_score(y_test, pred),3)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjF7s29rpcDw",
        "outputId": "3fe22b85-83b8-4de9-83a3-1de1a3b20f61"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측 정확도 0.617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using TF-IDF\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vect = TfidfVectorizer()\n",
        "tfidf_vect.fit(X_train)\n",
        "X_train_tfidf_vect =tfidf_vect.transform(X_train)\n",
        "X_test_tfidf_vect= tfidf_vect.transform(X_test)\n",
        "\n",
        "# Using Logistic\n",
        "\n",
        "lr_classfier = LogisticRegression(solver = 'liblinear')\n",
        "lr_classfier.fit(X_train_tfidf_vect, y_train)\n",
        "pred = lr_classfier.predict(X_test_tfidf_vect)"
      ],
      "metadata": {
        "id": "V9aFH1XxpOxs"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'예측 정확도 {round(accuracy_score(y_test, pred),3)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhB7OMSZqg2J",
        "outputId": "1a9a1cd4-312a-4bfa-f7b3-b39ba72c130d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측 정확도 0.678\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF 방식의 Vector Feature 처리가 더 높은 예측 성능을 보여줬다.\n",
        "\n",
        "\n",
        "일반적으로 텍스트가 많고 문서양이 많은 부분에 있어서는 TF-IDF 형식의 성능이 좋다.\n",
        "\n"
      ],
      "metadata": {
        "id": "jYcQ80bzqlNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " #Using Grid Search\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# dictionary class\n",
        "params =  {'C':[0.01,0.1,1,5,10]}\n",
        "# Model, params, cv, scoring part ..\n",
        "grid_lr = GridSearchCV(lr_classfier, param_grid = params, cv=3, scoring='accuracy', verbose =1)\n",
        "grid_lr.fit(X_train_tfidf_vect, y_train)\n",
        "print(grid_lr.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhxU4x7kq6GD",
        "outputId": "87f4da1d-3281-4873-c288-cf94bc9812c1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
            "{'C': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Precict with best Condition\n",
        "pred = grid_lr.predict(X_test_tfidf_vect)\n",
        "print(f'예측 정확도: {accuracy_score(y_test, pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCIC_riXsRE7",
        "outputId": "d74e6599-c7f5-472d-e3dc-01a253adbc53"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측 정확도: 0.6894583112055231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Pipeline for ML and this is example of pipeline\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "pipeline = Pipeline([\n",
        "  ('tfidf_vect',TfidfVectorizer(stop_words='english', ngram_range=(1,2), max_df =300)),\n",
        "  ('lr_clf',LogisticRegression(solver='liblinear',C=10))\n",
        "])"
      ],
      "metadata": {
        "id": "A6EN8F5ItlAP"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.fit(X_train, y_train)\n",
        "pred = pipeline.predict(X_test)"
      ],
      "metadata": {
        "id": "QGvkDte7uK5r"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Pipeline score: {round(accuracy_score(y_test, pred),2)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iXRQll_vRUs",
        "outputId": "362a9cc1-95d2-468f-a998-699013be4b44"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline score: 0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression 뿐만 아니라 SVM, Naive Bayes 등 다양한 분류 방식이 존재한다"
      ],
      "metadata": {
        "id": "lycn3-dSv9Dl"
      }
    }
  ]
}